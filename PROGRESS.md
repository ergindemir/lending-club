# Daily Progress

## 01/21-22
* Download Dataset
* Create github repo
* Study data dictionary
* Study pickling techniques and performance gain
* Basic eda and varibal transformations

## 01/23
* Detailed eda
* Filter columns with too many missing variables
* Split the dataset to continous and categorical variables
* Transform the dependent variable
* Fill the missing valules

## 01/24
* Evaluate the IV criterion for input variables
* Compile the dataset for modelling
* Encode categorical data for Random Forest and Logistic Regression seperately
* Transform variables engineer features
* Run test models and based on results:
  * Filter Columns that might carry leakage
  * Remove features with high correlation
  * Determine the most significant varibles

## 01/25 (Planned)
* Deeper study of models
* Generate confusion matrices and ROC curves
* Evaluate precision and recall and devise ways to improve them
* Look for data sources to calculte volatilty of NASDAQ
* Study the optimal choices to build a project Web Site
