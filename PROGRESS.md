# Daily Progress

## 01/21-22
* Download Dataset
* Create github repo
* Study data dictionary
* Study pickling techniques and performance gain
* Basic EDA and varibale transformations

## 01/23
* Detailed EDA
* Filter columns with too many missing variables
* Split the dataset into continous and categorical variables
* Transform the dependent variable
* Fill the missing valules

## 01/24
* Evaluate the IV criterion for input variables
* Compile the dataset for modelling
* Encode categorical data for Random Forest and Logistic Regression seperately
* Transform variables engineer features
* Run test models and based on results:
  * Filter Columns that might carry leakage
  * Remove features with high correlation
  * Determine the most significant varibles

## 01/25 (Planned)
* Deeper study of models
* Generate confusion matrices and ROC curves
* Evaluate precision and recall and devise ways to improve them
* Look for data sources to calculte volatilty of S&P 500
* Study the optimal choices to build a project Web Site
* Attend introductory course on Javascript
